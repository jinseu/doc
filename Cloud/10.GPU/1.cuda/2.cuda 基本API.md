## 1. 内存

### 1. 内存申请

**cudaHostAlloc**

**cudaMallocHost**

**cudaMallocManaged**

分配由Unified Memory 自动管理的内存，需要调用cudaFree释放

### 2. 内存复制

cuda 中关于内存复制的函数不是很多，主要有 `cudaMemcpy`, `cudaMemcpyPeer`, `cudaMemcpyAsync` 这三个函数。

**cudaMemcpy**

cudaMemcpy 函数原型如下，cudaMemcpy 的函数原型参数上类似于linux C `memcpy` 函数。不同之处在于，cudaMemcpy 不是在主机内存中的内存复制，而是将一段内存在主机和设备之间复制。于是复制的方向就有2*2可能性。

`__host__​cudaError_t cudaMemcpy ( void* dst, const void* src, size_t count, cudaMemcpyKind kind )`

cudaMemcpyKind可能值如下，其中除了cudaMemcpyDefault之外，其余四个值都可以从名字判断其含义。cudaMemcpyDefault 则表示有cuda运行时，根绝源目内存地址来推导，具体的复制方向。此时就会有一个问题，cuda运行时是如何进行推导的呢？事实上，cudaMemcpyDefault 参数有一个要求，只允许在支持 `unified virtual addressing`的系统上使用，在`unified virtual addressing`系统上，GPU内存被映射到主机内存地址空间内，这样通过判断指针的值所属范围，即可判断不同的指针指向的地址类型。

- cudaMemcpyHostToHost
- cudaMemcpyHostToDevice
- cudaMemcpyDeviceToHost
- cudaMemcpyDeviceToDevice
- cudaMemcpyDefault

此外，cudaMemcpy 是一个同步函数，只有在内存完全复制完成后，才会返回。这一点就是和 cudaMemcpyAsync 最大的区别。


**cudaMemcpyAsync** 

cudaMemcpyAsync 函数原型如下，相比于cudaMemcpy，cudaMemcpyAsync是异步的，同时多了一个stream参数，来制定具体在哪一个steam中执行。

`__host__​__device__​cudaError_t cudaMemcpyAsync ( void* dst, const void* src, size_t count, cudaMemcpyKind kind, cudaStream_t stream = 0 )`

For transfers from device memory to pageable host memory, the function will return only once the copy has completed.

For transfers from any host memory to any host memory, the function is fully synchronous with respect to the host.

For all other transfers, the function is fully asynchronous. If pageable memory must first be staged to pinned memory, this will be handled asynchronously with a worker thread.
